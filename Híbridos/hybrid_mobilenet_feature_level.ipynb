{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"bCrX20IFX9ko"},"outputs":[],"source":["#!pip install ultralytics opencv-python pillow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50203,"status":"ok","timestamp":1769791736401,"user":{"displayName":"Marcos Vin√≠cius","userId":"03427921222894808901"},"user_tz":180},"id":"rxDwlrvHk3iF","outputId":"a113bcdb-81b5-4aaf-e19c-0d760802d30f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABOPtd-MXEen"},"outputs":[],"source":["# ---------- Bibliotecas ----------\n","\n","import os\n","import shutil\n","import random\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","import yaml\n","import numpy as np\n","import cv2\n","import torch\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader, random_split\n","import timm\n","from sklearn.metrics import accuracy_score, f1_score\n","from itertools import product\n","from tqdm import tqdm\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import time\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1769791766215,"user":{"displayName":"Marcos Vin√≠cius","userId":"03427921222894808901"},"user_tz":180},"id":"aB0z-M29N1tE","outputId":"82da3e85-4b13-4d05-a4d0-392979380048"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["path = os.getcwd()\n","print(path)\n","\n","#os.chdir(path)\n","#file_log = open(path + \"/mensagem_final_classificar_V2.txt\", \"a\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDZ87AmYm0TX"},"outputs":[],"source":["# ================= Configura√ß√µes =================\n","NUM_CLASSES = 15\n","INPUT_SIZE = 224\n","BATCH_SIZE = 16\n","EPOCHS = 30\n","LR = 1e-3\n","PATIENCE = 5\n","\n","FUSION_MODE = \"concat\"  # \"concat\" OU \"sum\"\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","DATASET_FOLHA = \"/content/drive/MyDrive/TCC/Datasets/Imagens Folhas/Especies\"\n","DATASET_CASCA = \"/content/drive/MyDrive/TCC/Datasets/Imagens tronco/EspeciesCascas\"\n","\n","PESOS_FOLHA = \"/content/drive/MyDrive/TCC/Datasets/main_weights/folha/mobilenetv4_best_leaf.pt\"\n","PESOS_CASCA = \"/content/drive/MyDrive/TCC/Datasets/main_weights/casca/mobilenetv4_best_bark.pt\"\n","\n","CKPT_DIR = \"/content/drive/MyDrive/TCC/Datasets/checkpointsHybridFeature\"\n","FINAL_PATH = \"/content/drive/MyDrive/TCC/Datasets/main_weights/hybrid_mobilenet_best.pt\"\n","\n","os.makedirs(CKPT_DIR, exist_ok=True)"]},{"cell_type":"code","source":["def stratified_split(dataset, test_split=0.1, valid_split=0.2, seed=42):\n","    labels = [label for *_, label in dataset.samples]\n","\n","    sss1 = StratifiedShuffleSplit(\n","        n_splits=1,\n","        test_size=test_split,\n","        random_state=seed\n","    )\n","    train_valid_idx, test_idx = next(\n","        sss1.split(np.zeros(len(labels)), labels)\n","    )\n","\n","    labels_train_valid = np.array(labels)[train_valid_idx]\n","\n","    sss2 = StratifiedShuffleSplit(\n","        n_splits=1,\n","        test_size=valid_split,\n","        random_state=seed\n","    )\n","    train_idx, valid_idx = next(\n","        sss2.split(np.zeros(len(labels_train_valid)), labels_train_valid)\n","    )\n","\n","    train_idx = np.array(train_valid_idx)[train_idx]\n","    valid_idx = np.array(train_valid_idx)[valid_idx]\n","\n","    train_ds = torch.utils.data.Subset(dataset, train_idx)\n","    valid_ds = torch.utils.data.Subset(dataset, valid_idx)\n","    test_ds  = torch.utils.data.Subset(dataset, test_idx)\n","\n","    return train_ds, valid_ds, test_ds"],"metadata":{"id":"p4RVl59gnt0g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================= Dataset =================\n","class ImageFolderDataset(Dataset):\n","    def __init__(self, root_dir):\n","        self.samples = []\n","        classes = sorted(os.listdir(root_dir))\n","        self.class_to_idx = {c: i for i, c in enumerate(classes)}\n","\n","        for cls in classes:\n","            cls_path = os.path.join(root_dir, cls)\n","            if not os.path.isdir(cls_path):\n","                continue\n","            for f in os.listdir(cls_path):\n","                if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n","                    self.samples.append((os.path.join(cls_path, f),\n","                                         self.class_to_idx[cls]))\n","\n","    def preprocess(self, img_path):\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE))\n","        img = img.astype(np.float32) / 255.0\n","\n","        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n","        std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n","        img = (img - mean) / std\n","\n","        img = np.transpose(img, (2, 0, 1))\n","        return torch.from_numpy(img)\n","\n","class CartesianFusionDataset(Dataset):\n","    def __init__(self, ds_folha, ds_casca):\n","        self.samples = []\n","\n","        # Extrair samples considerando Subset\n","        def get_samples(ds):\n","            if isinstance(ds, torch.utils.data.Subset):\n","                # Pegar apenas os √≠ndices do subset\n","                base_samples = ds.dataset.samples\n","                return [base_samples[i] for i in ds.indices]\n","            else:\n","                return ds.samples\n","\n","        folha_samples = get_samples(ds_folha)\n","        casca_samples = get_samples(ds_casca)\n","\n","        # Agrupar por classe\n","        folhas_por_classe = {}\n","        cascas_por_classe = {}\n","\n","        for img, label in folha_samples:\n","            if label not in folhas_por_classe:\n","                folhas_por_classe[label] = []\n","            folhas_por_classe[label].append(img)\n","\n","        for img, label in casca_samples:\n","            if label not in cascas_por_classe:\n","                cascas_por_classe[label] = []\n","            cascas_por_classe[label].append(img)\n","\n","        # Produto cartesiano por classe\n","        for label in folhas_por_classe.keys():\n","            if label not in cascas_por_classe:\n","                continue\n","            for f_img in folhas_por_classe[label]:\n","                for c_img in cascas_por_classe[label]:\n","                    self.samples.append((f_img, c_img, label))\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        folha_path, casca_path, label = self.samples[idx]\n","\n","        # Preprocessar imagens\n","        img_f = self.preprocess(folha_path)\n","        img_c = self.preprocess(casca_path)\n","\n","        return img_f, img_c, torch.tensor(label, dtype=torch.long)\n","\n","    def preprocess(self, img_path):\n","        img = cv2.imread(img_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img = cv2.resize(img, (INPUT_SIZE, INPUT_SIZE))\n","        img = img.astype(np.float32) / 255.0\n","\n","        mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n","        std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n","        img = (img - mean) / std\n","\n","        img = np.transpose(img, (2, 0, 1))\n","        return torch.from_numpy(img)"],"metadata":{"id":"xY9emgZYoD8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================= Feature Extractors =================\n","def create_feature_extractor(weight_path):\n","    # 1. Carregar modelo COMPLETO primeiro\n","    model_full = timm.create_model(\n","        'mobilenetv4_conv_small.e1200_r224_in1k',\n","        pretrained=False,\n","        num_classes=15  # ‚Üê MESMO n√∫mero do treinamento\n","    )\n","    model_full.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n","\n","    # 2. Criar feature extractor\n","    model = timm.create_model(\n","        'mobilenetv4_conv_small.e1200_r224_in1k',\n","        pretrained=False,\n","        num_classes=0  # ‚Üê Sem classifier\n","    )\n","\n","    # 3. Copiar pesos do backbone (tudo exceto classifier)\n","    model_dict = model.state_dict()\n","    pretrained_dict = {k: v for k, v in model_full.state_dict().items() if k in model_dict}\n","    model.load_state_dict(pretrained_dict)\n","\n","    # 4. Congelar\n","    for p in model.parameters():\n","        p.requires_grad = False\n","    model.eval()\n","\n","    return model.to(DEVICE)"],"metadata":{"id":"JBPrZDL-oGn4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================= MLP =================\n","class FusionMLP(nn.Module):\n","    def __init__(self, in_dim):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(in_dim, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, NUM_CLASSES)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"dMvh3_KnoI0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================= Avalia√ß√£o =================\n","@torch.no_grad()\n","def evaluate(model_f, model_c, mlp, loader):\n","    mlp.eval()\n","    preds, labels_all = [], []\n","    inference_times = []  # ‚Üê NOVO\n","\n","    for img_f, img_c, labels in loader:\n","        img_f, img_c = img_f.to(DEVICE), img_c.to(DEVICE)\n","\n","        # ‚Üê NOVO: Medir tempo\n","        start_time = time.time()\n","\n","        feat_f = model_f(img_f)\n","        feat_c = model_c(img_c)\n","\n","        fused = torch.cat([feat_f, feat_c], 1) if FUSION_MODE == \"concat\" else feat_f + feat_c\n","        out = mlp(fused)\n","\n","        end_time = time.time()\n","        batch_time = end_time - start_time\n","        inference_times.append(batch_time / img_f.size(0))  # Tempo por imagem\n","\n","        preds.extend(torch.argmax(out, 1).cpu().numpy())\n","        labels_all.extend(labels.numpy())\n","\n","    acc = accuracy_score(labels_all, preds)\n","    f1 = f1_score(labels_all, preds, average=\"weighted\")\n","    avg_time = np.mean(inference_times) * 1000  # ‚Üê NOVO: em milissegundos\n","\n","    return acc, f1, avg_time, preds, labels_all  # ‚Üê NOVO: retorna tempo, preds e labels"],"metadata":{"id":"mnfVqVjUoL_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================= Fun√ß√µes de An√°lise =================\n","def plot_confusion_matrix(y_true, y_pred, class_names, title=\"Matriz de Confus√£o\", normalize=False):\n","    \"\"\"\n","    Plota matriz de confus√£o com visualiza√ß√£o aprimorada.\n","\n","    Args:\n","        y_true: Labels verdadeiros\n","        y_pred: Predi√ß√µes do modelo\n","        class_names: Lista com nomes das classes\n","        title: T√≠tulo do gr√°fico\n","        normalize: Se True, normaliza os valores por linha (%)\n","    \"\"\"\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        fmt = '.2%'\n","    else:\n","        fmt = 'd'\n","\n","    plt.figure(figsize=(12, 10))\n","    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n","                xticklabels=class_names, yticklabels=class_names,\n","                cbar_kws={'label': 'Porcentagem' if normalize else 'Contagem'})\n","    plt.title(title, fontsize=14, fontweight='bold')\n","    plt.ylabel('Classe Verdadeira', fontsize=12)\n","    plt.xlabel('Classe Predita', fontsize=12)\n","    plt.xticks(rotation=45, ha='right')\n","    plt.yticks(rotation=0)\n","    plt.tight_layout()\n","    plt.show()\n","\n","def print_per_class_accuracy(y_true, y_pred, class_names):\n","    \"\"\"\n","    Imprime acur√°cia por classe e outras m√©tricas detalhadas.\n","\n","    Args:\n","        y_true: Labels verdadeiros\n","        y_pred: Predi√ß√µes do modelo\n","        class_names: Lista com nomes das classes\n","    \"\"\"\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"ACUR√ÅCIA POR CLASSE\")\n","    print(\"=\"*80)\n","    print(f\"{'Classe':<25} {'Corretas':>10} {'Total':>10} {'Acur√°cia':>12}\")\n","    print(\"-\"*80)\n","\n","    per_class_acc = []\n","    for i, class_name in enumerate(class_names):\n","        correct = cm[i, i]\n","        total = cm[i, :].sum()\n","        acc = correct / total if total > 0 else 0\n","        per_class_acc.append(acc)\n","        print(f\"{class_name:<25} {correct:>10} {total:>10} {acc:>12.2%}\")\n","\n","    print(\"-\"*80)\n","    print(f\"{'M√âDIA':<25} {'':<10} {'':<10} {np.mean(per_class_acc):>12.2%}\")\n","    print(\"=\"*80)\n","\n","    # Relat√≥rio de classifica√ß√£o detalhado\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"RELAT√ìRIO DE CLASSIFICA√á√ÉO DETALHADO\")\n","    print(\"=\"*80)\n","    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n","\n","    return per_class_acc"],"metadata":{"id":"P_Tmqv43QuVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ================= Treinamento =================\n","def train(model_f, model_c, mlp, train_loader, valid_loader):\n","    optimizer = optim.Adam(mlp.parameters(), lr=LR)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    best_f1 = 0\n","    patience_counter = 0\n","    best_preds = None  # ‚Üê NOVO\n","    best_labels = None  # ‚Üê NOVO\n","    early_stop = False\n","\n","    # === Tentar carregar √∫ltimo checkpoint existente ===\n","    os.makedirs(CKPT_DIR, exist_ok=True)\n","\n","    # Procura checkpoints com o padr√£o \"hybrid_feature_epochX_eY_lrZ_modeM.pt\"\n","    ckpt_pattern = f\"e{EPOCHS:.0e}_lr{LR:.0e}_mode{FUSION_MODE}\"\n","    ckpt_files = [f for f in os.listdir(CKPT_DIR) if ckpt_pattern in f]\n","    last_epoch = 0\n","\n","    if ckpt_files:\n","        # Ordena checkpoints por n√∫mero da √©poca\n","        ckpt_files.sort(key=lambda x: int(x.split(\"_epoch\")[1].split(\"_\")[0]))\n","        last_ckpt = os.path.join(CKPT_DIR, ckpt_files[-1])\n","        print(f\"Checkpoint detectado: {last_ckpt} ‚Äî retomando treinamento...\")\n","\n","        checkpoint = torch.load(last_ckpt, map_location=DEVICE)\n","        mlp.load_state_dict(checkpoint['mlp_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        last_epoch = checkpoint['epoch']\n","        best_f1 = checkpoint.get('best_f1', 0.0)\n","        patience_counter = checkpoint.get('patience_counter', 0)\n","\n","        # Testa se j√° chegou no final do treinamento\n","        if last_epoch == EPOCHS:\n","            print(\"Treinamento j√° foi finalizado!\")\n","            acc_val, f1_val = checkpoint['val_acc'], checkpoint['val_f1']\n","            print(f\"Epoch {last_epoch}/{EPOCHS} - val_acc: {acc_val:.4f}, val_f1: {f1_val:.4f}\")\n","\n","            # Retornar predi√ß√µes salvas (se existirem)\n","            if 'best_preds' in checkpoint and 'best_labels' in checkpoint:\n","                return checkpoint['best_preds'], checkpoint['best_labels']\n","            else:\n","                # Avaliar para obter predi√ß√µes\n","                _, _, _, preds, labels = evaluate(model_f, model_c, mlp, valid_loader)\n","                return preds, labels\n","        else:\n","            print(f\"Retomando a partir da √©poca {last_epoch+1}/{EPOCHS} (lr={LR})\")\n","    else:\n","        print(\"Nenhum checkpoint anterior encontrado, come√ßando do zero.\")\n","\n","    # === Loop de Treinamento ===\n","    for epoch in range(last_epoch, EPOCHS):\n","        mlp.train()\n","        running_loss = 0.0\n","\n","        for img_f, img_c, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n","            img_f, img_c, y = img_f.to(DEVICE), img_c.to(DEVICE), y.to(DEVICE)\n","\n","            with torch.no_grad():\n","                feat_f = model_f(img_f)\n","                feat_c = model_c(img_c)\n","\n","            fused = (\n","                torch.cat([feat_f, feat_c], 1)\n","                if FUSION_MODE == \"concat\"\n","                else feat_f + feat_c\n","            )\n","\n","            out = mlp(fused)\n","            loss = criterion(out, y)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * img_f.size(0)\n","\n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        acc, f1, avg_time, preds, labels = evaluate(model_f, model_c, mlp, valid_loader)\n","\n","        print(f\"Epoch {epoch+1}/{EPOCHS} - loss: {epoch_loss:.4f}, val_acc: {acc:.4f}, val_f1: {f1:.4f}, time: {avg_time:.2f}ms\")\n","\n","        # === Early Stopping por val_f1 ===\n","        if f1 > best_f1:\n","            best_f1 = f1\n","            patience_counter = 0\n","            best_model_state = mlp.state_dict().copy()\n","            best_preds = preds\n","            best_labels = labels\n","            best_epoch = epoch + 1\n","            print(f\"  ‚úÖ Novo melhor F1: {f1:.4f}\")\n","        else:\n","            patience_counter += 1\n","            print(f\"  ‚è≥ Contador do Early stopping: {patience_counter}/{PATIENCE} - Melhor F1-Score anterior: {best_f1:.4f}\")\n","\n","            if patience_counter >= PATIENCE:\n","                print(f\"  üõë Parando antecipadamente na √©poca {epoch+1}. Melhor val_f1: {best_f1:.4f}\")\n","                early_stop = True\n","\n","        # === Salvar checkpoint por √©poca ===\n","        if early_stop:\n","            # Salva a √©poca atual como se fosse a √∫ltima\n","            current_epoch = EPOCHS\n","            ckpt_path = os.path.join(CKPT_DIR,\n","                                    f\"hybrid_feature_epoch{EPOCHS}_e{EPOCHS:.0e}_lr{LR:.0e}_mode{FUSION_MODE}.pt\")\n","        else:\n","            current_epoch = epoch + 1\n","            ckpt_path = os.path.join(CKPT_DIR,\n","                                    f\"hybrid_feature_epoch{current_epoch}_e{EPOCHS:.0e}_lr{LR:.0e}_mode{FUSION_MODE}.pt\")\n","\n","        torch.save({\n","            'epoch': current_epoch,\n","            'mlp_state_dict': mlp.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'val_acc': acc,\n","            'val_f1': f1,\n","            'loss': epoch_loss,\n","            'lr': LR,\n","            'best_f1': best_f1,\n","            'patience_counter': patience_counter,\n","            'best_preds': best_preds,\n","            'best_labels': best_labels,\n","            'fusion_mode': FUSION_MODE\n","        }, ckpt_path)\n","        print(f\"  üíæ Checkpoint salvo: {ckpt_path}\")\n","\n","        # Apagar checkpoint anterior\n","        prev_ckpt = os.path.join(CKPT_DIR,\n","                                f\"hybrid_feature_epoch{epoch}_e{EPOCHS:.0e}_lr{LR:.0e}_mode{FUSION_MODE}.pt\")\n","        if os.path.exists(prev_ckpt):\n","            os.remove(prev_ckpt)\n","            print(f\"  üóëÔ∏è  Checkpoint deletado: {prev_ckpt}\")\n","\n","        if early_stop:\n","            break  # Early Stopping\n","\n","    # === Restaurar melhor modelo ===\n","    if best_model_state is not None:\n","        print(f\"\\nüîÑ Restaurando melhor modelo (√©poca {best_epoch}, F1={best_f1:.4f})\")\n","        mlp.load_state_dict(best_model_state)\n","\n","        # Salvar melhor modelo no caminho final\n","        torch.save(best_model_state, FINAL_PATH)\n","        print(f\"üíæ Melhor modelo salvo em: {FINAL_PATH}\")\n","\n","    return best_preds, best_labels  # ‚Üê NOVO: retorna predi√ß√µes da melhor √©poca"],"metadata":{"id":"6zVzvjDioMiw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v0zrpn9VnK1m"},"outputs":[],"source":["# === Fun√ß√£o Main ===\n","if __name__ == \"__main__\":\n","    try:\n","        print(\n","            \"\\n--------------- Treinamento do Modelo H√≠brido 2 - MobileNetV4 ---------------\"\n","            \"\\nIn√≠cio...\"\n","        )\n","\n","        # 1. Dividir datasets originais\n","        ds_f = ImageFolderDataset(DATASET_FOLHA)\n","        print(f\"Dataset de Folhas:\\nClasses detectadas ({len(ds_f.class_to_idx.keys())}): {ds_f.class_to_idx.keys()}\")\n","        print(f\"Total de Imagens: {len(ds_f)}\")\n","        train_f, valid_f, test_f = stratified_split(ds_f)\n","        print(f\"Total: {len(train_f)+len(valid_f)+len(test_f)} | Treino: {len(train_f)} | Valida√ß√£o: {len(valid_f)} | Teste: {len(test_f)}\\n\")\n","\n","        ds_c = ImageFolderDataset(DATASET_CASCA)\n","        print(f\"Dataset de Cascas:\\nClasses detectadas ({len(ds_c.class_to_idx.keys())}): {ds_c.class_to_idx.keys()}\")\n","        print(f\"Total de Imagens: {len(ds_c)}\")\n","        train_c, valid_c, test_c = stratified_split(ds_c)\n","        print(f\"Total: {len(train_c)+len(valid_c)+len(test_c)} | Treino: {len(train_c)} | Valida√ß√£o: {len(valid_c)} | Teste: {len(test_c)}\\n\")\n","\n","        # 2. Criar produto cartesiano DEPOIS\n","        train_fusion = CartesianFusionDataset(train_f, train_c)\n","        valid_fusion = CartesianFusionDataset(valid_f, valid_c)\n","        test_fusion = CartesianFusionDataset(test_f, test_c)\n","\n","        #fusion = CartesianFusionDataset(ds_f.dataset, ds_c.dataset)\n","        #train_fusion, valid_fusion, test_fusion = stratified_split(fusion)\n","\n","        # Extra. Exibir dados do Dataset ---------------------------------------- DEBUG ------------------------------------------------------------------------------------------\n","        print(f\"Total: {len(train_fusion)+len(valid_fusion)+len(test_fusion)} | Treino: {len(train_fusion)} | Valida√ß√£o: {len(valid_fusion)} | Teste: {len(test_fusion)}\")\n","\n","        print(\"\\n=== DEBUG ===\")\n","\n","        # Verificar quantas classes est√£o presentes em cada split\n","        def check_classes(fusion_ds, name):\n","            classes_presentes = set()\n","            for _, _, label in fusion_ds.samples:\n","                classes_presentes.add(label)\n","            print(f\"{name}: {len(classes_presentes)} classes presentes de 15 totais\")\n","            print(f\"Classes: {sorted(classes_presentes)}\")\n","            return classes_presentes\n","\n","        train_classes = check_classes(train_fusion, \"Train\")\n","        valid_classes = check_classes(valid_fusion, \"Valid\")\n","        test_classes = check_classes(test_fusion, \"Test\")\n","\n","        # Verificar se h√° classes faltando\n","        all_classes = set(range(15))\n","        print(f\"\\nClasses faltando em train: {all_classes - train_classes}\")\n","        print(f\"Classes faltando em valid: {all_classes - valid_classes}\")\n","        print(f\"Classes faltando em test: {all_classes - test_classes}\")\n","\n","        # Pares por classe em cada split\n","        def count_pairs_per_class(fusion_ds, name):\n","            pares_por_classe = {}\n","            for _, _, label in fusion_ds.samples:\n","                pares_por_classe[label] = pares_por_classe.get(label, 0) + 1\n","\n","            print(f\"\\n{name} - Pares por classe:\")\n","            for label in sorted(pares_por_classe.keys()):\n","                print(f\"  Classe {label}: {pares_por_classe[label]:4d} pares\")\n","            print(f\"Total: {sum(pares_por_classe.values())}\")\n","\n","        count_pairs_per_class(train_fusion, \"TREINO\")\n","        count_pairs_per_class(valid_fusion, \"VALIDA√á√ÉO\")\n","        count_pairs_per_class(test_fusion, \"TESTE\")\n","\n","        # -------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","        # 3. Criar DataLoaders\n","        train_loader = DataLoader(train_fusion, batch_size=BATCH_SIZE, shuffle=True)\n","        valid_loader = DataLoader(valid_fusion, batch_size=BATCH_SIZE, shuffle=False)\n","        test_loader = DataLoader(test_fusion, batch_size=BATCH_SIZE, shuffle=False)\n","\n","        # üîπ Modelos base (feature extractors)\n","        model_f = create_feature_extractor(PESOS_FOLHA).to(DEVICE)\n","        model_c = create_feature_extractor(PESOS_CASCA).to(DEVICE)\n","\n","        model_f.eval()\n","        model_c.eval()\n","\n","        for p in model_f.parameters():\n","            p.requires_grad = False\n","        for p in model_c.parameters():\n","            p.requires_grad = False\n","\n","        # üîπ Dimens√£o das features\n","        feat_dim = model_f.num_features\n","        if FUSION_MODE == \"concat\":\n","            feat_dim *= 2\n","\n","        # üîπ MLP de fus√£o\n","        mlp = FusionMLP(feat_dim).to(DEVICE)\n","\n","        # üîπ Treinamento (somente MLP)\n","        print(f\"\\n{'='*80}\")\n","        print(f\"TREINAMENTO DA MLP - FUSION_MODE: {FUSION_MODE}\")\n","        print(f\"{'='*80}\\n\")\n","\n","        best_preds_val, best_labels_val = train(  # ‚Üê ATUALIZADO\n","            model_f,\n","            model_c,\n","            mlp,\n","            train_loader,\n","            valid_loader\n","        )\n","\n","        # Carregar melhor modelo\n","        mlp.load_state_dict(torch.load(FINAL_PATH))\n","\n","        # ‚Üê NOVO: Avaliar no test\n","        print(f\"\\n{'='*80}\")\n","        print(f\"AVALIA√á√ÉO FINAL NO CONJUNTO DE TESTE\")\n","        print(f\"{'='*80}\\n\")\n","\n","        acc_test, f1_test, time_test, preds_test, labels_test = evaluate(model_f, model_c, mlp, test_loader)\n","\n","        print(f\"\\nüéØ TESTE FINAL:\")\n","        print(f\"   Accuracy: {acc_test:.4f}\")\n","        print(f\"   F1-Score: {f1_test:.4f}\")\n","        print(f\"   Tempo m√©dio de infer√™ncia: {time_test:.2f} ms/imagem\")\n","\n","        # ‚Üê NOVO: Obter nomes das classes\n","        class_names = list(ds_f.class_to_idx.keys())\n","\n","        # ‚Üê NOVO: An√°lise detalhada\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"AN√ÅLISE DETALHADA - FEATURE-LEVEL FUSION\")\n","        print(\"=\"*80)\n","        per_class_acc = print_per_class_accuracy(labels_test, preds_test, class_names)\n","\n","        # ‚Üê NOVO: Matriz de confus√£o\n","        plot_confusion_matrix(labels_test, preds_test, class_names,\n","                             title=f\"Matriz de Confus√£o - Feature-Level Fusion ({FUSION_MODE.upper()})\",\n","                             normalize=True) #OBS: Normalize deixa como porcentagem, n√£o n√∫mero bruto\n","\n","        print(\"...Fim\\n\")\n","\n","    except KeyboardInterrupt:\n","        print(\"Programa encerrado via terminal...\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}